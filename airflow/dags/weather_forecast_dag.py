import os
import csv
import requests
import psycopg2
from datetime import datetime, date, timedelta

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago # ƒê∆∞·ª£c s·ª≠ d·ª•ng cho start_date
from dotenv import load_dotenv

load_dotenv()

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

provinces = [
    {"name": "An Giang", "lat": 10.521, "lon": 105.125},
    {"name": "B√† R·ªãa - V≈©ng T√†u", "lat": 10.541, "lon": 107.242},
    {"name": "B·∫°c Li√™u", "lat": 9.294, "lon": 105.724},
    {"name": "B·∫Øc Giang", "lat": 21.273, "lon": 106.194},
    {"name": "B·∫Øc K·∫°n", "lat": 22.147, "lon": 105.834},
    {"name": "B·∫Øc Ninh", "lat": 21.186, "lon": 106.076},
    {"name": "B·∫øn Tre", "lat": 10.243, "lon": 106.375},
    {"name": "B√¨nh D∆∞∆°ng", "lat": 11.325, "lon": 106.477},
    {"name": "B√¨nh ƒê·ªãnh", "lat": 14.166, "lon": 108.902},
    {"name": "B√¨nh Ph∆∞·ªõc", "lat": 11.751, "lon": 106.723},
    {"name": "B√¨nh Thu·∫≠n", "lat": 11.090, "lon": 108.072},
    {"name": "C√† Mau", "lat": 9.176, "lon": 105.152},
    {"name": "Cao B·∫±ng", "lat": 22.665, "lon": 106.257},
    {"name": "C·∫ßn Th∆°", "lat": 10.045, "lon": 105.746},
    {"name": "ƒê√† N·∫µng", "lat": 16.047, "lon": 108.206},
    {"name": "ƒê·∫Øk L·∫Øk", "lat": 12.710, "lon": 108.237},
    {"name": "ƒê·∫Øk N√¥ng", "lat": 12.264, "lon": 107.609},
    {"name": "ƒêi·ªán Bi√™n", "lat": 21.383, "lon": 103.016},
    {"name": "ƒê·ªìng Nai", "lat": 10.948, "lon": 106.824},
    {"name": "ƒê·ªìng Th√°p", "lat": 10.535, "lon": 105.636},
    {"name": "Gia Lai", "lat": 13.807, "lon": 108.109},
    {"name": "H√† Giang", "lat": 22.750, "lon": 104.983},
    {"name": "H√† Nam", "lat": 20.583, "lon": 105.922},
    {"name": "H√† N·ªôi", "lat": 21.028, "lon": 105.854},
    {"name": "H√† Tƒ©nh", "lat": 18.342, "lon": 105.905},
    {"name": "H·∫£i D∆∞∆°ng", "lat": 20.938, "lon": 106.330},
    {"name": "H·∫£i Ph√≤ng", "lat": 20.844, "lon": 106.688},
    {"name": "H·∫≠u Giang", "lat": 9.757, "lon": 105.641},
    {"name": "H√≤a B√¨nh", "lat": 20.817, "lon": 105.337},
    {"name": "H∆∞ng Y√™n", "lat": 20.646, "lon": 106.051},
    {"name": "Kh√°nh H√≤a", "lat": 12.259, "lon": 109.196},
    {"name": "Ki√™n Giang", "lat": 10.012, "lon": 105.080},
    {"name": "Kon Tum", "lat": 14.349, "lon": 108.000},
    {"name": "Lai Ch√¢u", "lat": 22.396, "lon": 103.458},
    {"name": "L√¢m ƒê·ªìng", "lat": 11.575, "lon": 108.142},
    {"name": "L·∫°ng S∆°n", "lat": 21.853, "lon": 106.761},
    {"name": "L√†o Cai", "lat": 22.485, "lon": 103.970},
    {"name": "Long An", "lat": 10.543, "lon": 106.411},
    {"name": "Nam ƒê·ªãnh", "lat": 20.438, "lon": 106.162},
    {"name": "Ngh·ªá An", "lat": 19.234, "lon": 104.920},
    {"name": "Ninh B√¨nh", "lat": 20.250, "lon": 105.974},
    {"name": "Ninh Thu·∫≠n", "lat": 11.564, "lon": 108.988},
    {"name": "Ph√∫ Th·ªç", "lat": 21.345, "lon": 105.254},
    {"name": "Ph√∫ Y√™n", "lat": 13.088, "lon": 109.092},
    {"name": "Qu·∫£ng B√¨nh", "lat": 17.468, "lon": 106.622},
    {"name": "Qu·∫£ng Nam", "lat": 15.539, "lon": 108.019},
    {"name": "Qu·∫£ng Ng√£i", "lat": 15.120, "lon": 108.800},
    {"name": "Qu·∫£ng Ninh", "lat": 21.006, "lon": 107.292},
    {"name": "Qu·∫£ng Tr·ªã", "lat": 16.744, "lon": 107.189},
    {"name": "S√≥c TrƒÉng", "lat": 9.602, "lon": 105.973},
    {"name": "S∆°n La", "lat": 21.325, "lon": 103.918},
    {"name": "T√¢y Ninh", "lat": 11.365, "lon": 106.098},
    {"name": "Th√°i B√¨nh", "lat": 20.446, "lon": 106.342},
    {"name": "Th√°i Nguy√™n", "lat": 21.594, "lon": 105.848},
    {"name": "Thanh H√≥a", "lat": 19.807, "lon": 105.776},
    {"name": "Th·ª´a Thi√™n Hu·∫ø", "lat": 16.463, "lon": 107.590},
    {"name": "Ti·ªÅn Giang", "lat": 10.449, "lon": 106.342},
    {"name": "TP H·ªì Ch√≠ Minh", "lat": 10.776, "lon": 106.700},
    {"name": "Tr√† Vinh", "lat": 9.812, "lon": 106.299},
    {"name": "Tuy√™n Quang", "lat": 21.823, "lon": 105.218},
    {"name": "Vƒ©nh Long", "lat": 10.253, "lon": 105.973},
    {"name": "Vƒ©nh Ph√∫c", "lat": 21.308, "lon": 105.604},
    {"name": "Y√™n B√°i", "lat": 21.705, "lon": 104.870}
]

def fetch_weather_data(**context):
    today = date.today()
    today_iso = today.isoformat()
    end_date = today + timedelta(days=2)
    
    os.makedirs("/opt/airflow/weather_data", exist_ok=True)
    
    csv_file = f"/opt/airflow/weather_data/{today_iso}_{end_date.isoformat()}.csv"
    header = ["Province", "Time", "Temperature", "Temp_Max", "Temp_Min", "Precipitation", "Windspeed_Max", "UV_Index_Max", "Sunshine_Hours", "Sundown_Hours", "Weather_Code", "Humidity", "Feel_Like"]
    
    with open(csv_file, mode="w", newline='', encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(header)

        for province in provinces:
            url = "https://api.open-meteo.com/v1/forecast"
            params = {
                "latitude": province["lat"],
                "longitude": province["lon"],
                "hourly": "temperature_2m,precipitation,windspeed_10m,uv_index,weathercode,sunshine_duration,relativehumidity_2m,apparent_temperature",
                "timezone": "Asia/Bangkok",
                "start_date": today_iso,
                "end_date": end_date.isoformat()
            }

            response = requests.get(url, params=params)
            if response.status_code == 200:
                data = response.json().get("hourly", {})
                times = data.get("time", []) # Th√™m .get ƒë·ªÉ tr√°nh l·ªói n·∫øu key kh√¥ng t·ªìn t·∫°i
                temps = data.get("temperature_2m", [])
                precs = data.get("precipitation", [])
                winds = data.get("windspeed_10m", [])
                uvs = data.get("uv_index", [])
                weathercodes = data.get("weathercode", [])
                sunshines = data.get("sunshine_duration", [0]*len(times))
                humidity = data.get("relativehumidity_2m", [])
                feel_like = data.get("apparent_temperature", [])

                # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu time th√¨ b·ªè qua t·ªânh n√†y
                if not times:
                    print(f"‚ö†Ô∏è {province['name']}: kh√¥ng c√≥ d·ªØ li·ªáu 'time' t·ª´ API, b·ªè qua.")
                    continue

                day_indices = {}
                for idx, t in enumerate(times):
                    day = t.split("T")[0]
                    if day not in day_indices:
                        day_indices[day] = []
                    day_indices[day].append(idx)

                for i, t in enumerate(times):
                    hour = int(t.split("T")[1][:2])
                    if hour % 3 != 0:
                        continue
                    day = t.split("T")[0]
                    indices = day_indices.get(day, []) # Th√™m .get ƒë·ªÉ tr√°nh l·ªói n·∫øu key kh√¥ng t·ªìn t·∫°i
                    if not indices: # N·∫øu kh√¥ng c√≥ indices cho ng√†y ƒë√≥ th√¨ b·ªè qua
                        continue
                        
                    temp_max = max([temps[j] for j in indices if j < len(temps)])
                    temp_min = min([temps[j] for j in indices if j < len(temps)])
                    wind_max = max([winds[j] for j in indices if j < len(winds)])
                    uv_max = max([uvs[j] for j in indices if j < len(uvs)])
                    sunshine_hours = sum([sunshines[j] for j in indices if j < len(sunshines) and 6 <= int(times[j].split("T")[1][:2]) < 18]) / 3600
                    sundown_hours = len([j for j in indices if j < len(times) and (int(times[j].split("T")[1][:2]) < 6 or int(times[j].split("T")[1][:2]) >= 18)])
                    
                    # ƒê·∫£m b·∫£o index i kh√¥ng v∆∞·ª£t qu√° ƒë·ªô d√†i c·ªßa c√°c list
                    current_temp = temps[i] if i < len(temps) else None
                    current_prec = precs[i] if i < len(precs) else None
                    current_weathercode = weathercodes[i] if i < len(weathercodes) else None
                    current_humidity = humidity[i] if i < len(humidity) else None
                    current_feel_like = feel_like[i] if i < len(feel_like) else None

                    row = [
                        province["name"],
                        t,
                        current_temp,
                        temp_max,
                        temp_min,
                        current_prec,
                        wind_max,
                        uv_max,
                        round(sunshine_hours, 2),
                        sundown_hours,
                        current_weathercode,
                        current_humidity,
                        current_feel_like
                    ]
                    writer.writerow(row)
                print(f"‚úÖ {province['name']}: xong")
            else:
                print(f"‚ùå {province['name']}: l·ªói API - Status {response.status_code}")

    print(f"\nüìÑ ƒê√£ l∆∞u v√†o file: {csv_file}")
    return csv_file

def import_to_database(**context):
    ti = context['ti']
    csv_file_path = ti.xcom_pull(task_ids='fetch_weather_data')
    
    if not csv_file_path or not os.path.exists(csv_file_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file CSV: {csv_file_path}. B·ªè qua import.")
        return

    today = date.today() # D√πng ng√†y hi·ªán t·∫°i khi task ch·∫°y ƒë·ªÉ x√°c ƒë·ªãnh kho·∫£ng d·ªØ li·ªáu
    start_of_data_period_iso = os.path.basename(csv_file_path).split('_')[0]
    end_of_data_period_iso = os.path.basename(csv_file_path).split('_')[1].replace(".csv", "")
    
    # Chuy·ªÉn ƒë·ªïi ng√†y t·ª´ t√™n file v·ªÅ datetime.date ƒë·ªÉ d√πng trong query
    try:
        # start_date_for_delete = datetime.strptime(start_of_data_period_iso, '%Y-%m-%d').date()
        # end_date_for_delete = datetime.strptime(end_of_data_period_iso, '%Y-%m-%d').date()
        
        # D√πng ng√†y h√¥m nay v√† 2 ng√†y t·ªõi, t∆∞∆°ng ·ª©ng v·ªõi logic c√†o d·ªØ li·ªáu
        start_date_for_delete = date.today()
        end_date_for_delete = start_date_for_delete + timedelta(days=2)


    except ValueError as e:
        print(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi ng√†y t·ª´ t√™n file: {e}. S·ª≠ d·ª•ng ng√†y m·∫∑c ƒë·ªãnh.")
        start_date_for_delete = date.today()
        end_date_for_delete = start_date_for_delete + timedelta(days=2)


    connection = None
    try:
        connection = psycopg2.connect(
            dbname=os.environ.get("DATABASE_NAME"),
            user=os.environ.get("DATABASE_USER"),
            password=os.environ.get("DATABASE_PASSWORD"),
            host=os.environ.get("DATABASE_HOST"),
            port=os.environ.get("DATABASE_PORT")
        )
        
        cursor = connection.cursor()
        table_name = os.environ.get("WEATHER_DATA_TABLE_NAME", "weather_data")

        print(f"B·∫Øt ƒë·∫ßu nh·∫≠p d·ªØ li·ªáu t·ª´ {csv_file_path} v√†o b·∫£ng {table_name}...")
        
        with open(csv_file_path, mode="r", encoding="utf-8-sig") as file_obj:
            next(file_obj)
            
            # X√≥a d·ªØ li·ªáu c≈© trong kho·∫£ng th·ªùi gian m·ªõi ƒë·ªÉ tr√°nh tr√πng l·∫∑p
            # D·ªØ li·ªáu 'Time' trong DB l√† timestamp, c·∫ßn ƒë·∫£m b·∫£o so s√°nh ƒë√∫ng ki·ªÉu
            # V√≠ d·ª•: Time >= '2023-01-01 00:00:00' AND Time <= '2023-01-03 23:59:59'
            delete_start_timestamp = datetime.combine(start_date_for_delete, datetime.min.time())
            delete_end_timestamp = datetime.combine(end_date_for_delete, datetime.max.time())

            print(f"X√≥a d·ªØ li·ªáu c≈© trong kho·∫£ng: {delete_start_timestamp} ƒë·∫øn {delete_end_timestamp}")
            
            cursor.execute(
                f"""
                DELETE FROM {table_name}
                WHERE "Time" >= %s AND "Time" <= %s
                """,
                (delete_start_timestamp, delete_end_timestamp)
            )
            
            # COPY d·ªØ li·ªáu m·ªõi
            copy_sql = f"""
                COPY {table_name} (
                    "Province", "Time", "Temperature", "Temp_Max", "Temp_Min", "Precipitation", 
                    "Windspeed_Max", "UV_Index_Max", "Sunshine_Hours", "Sundown_Hours", 
                    "Weather_Code", "Humidity", "Feel_Like"
                )
                FROM STDIN
                WITH (FORMAT CSV, HEADER FALSE);
            """
            cursor.copy_expert(sql=copy_sql, file=file_obj)
            
        connection.commit()
        print("‚úÖ D·ªØ li·ªáu t·ª´ file CSV ƒë√£ ƒë∆∞·ª£c nh·∫≠p v√†o c∆° s·ªü d·ªØ li·ªáu th√†nh c√¥ng!")

    except Exception as e:
        print(f"‚ùå L·ªói khi nh·∫≠p d·ªØ li·ªáu v√†o database: {e}")
        if connection:
            connection.rollback()
    finally:
        if connection:
            cursor.close()
            connection.close()
            print("‚ÑπÔ∏è ƒê√£ ƒë√≥ng k·∫øt n·ªëi t·ªõi PostgreSQL.")

with DAG(
    dag_id='weather_forecast_dag', 
    default_args=default_args,
    description='C√†o d·ªØ li·ªáu th·ªùi ti·∫øt t·ª´ API m·ªói 3 ng√†y v√† l∆∞u v√†o database',
    schedule_interval=timedelta(days=3),
    start_date=days_ago(1), # B·∫Øt ƒë·∫ßu t√≠nh t·ª´ ng√†y h√¥m qua l√∫c 00:00
    catchup=False,
    tags=['weather'],
) as dag:

    fetch_task = PythonOperator(
        task_id='fetch_weather_data',
        python_callable=fetch_weather_data,
        # provide_context=True,
    )

    import_task = PythonOperator(
        task_id='import_to_database',
        python_callable=import_to_database,
        # provide_context=True, 
    )

    fetch_task >> import_task